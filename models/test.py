import numpy as np
from layers import Dense, SquaredError, GradientDescent, lr_schedule
from model import Sequential, load_model
import matplotlib.pyplot as plt

def create_model():
    model = Sequential(output_shape=10)

    model.add(Dense(units=5, activation="relu"))
    model.add(Dense(units=7, activation="relu"))
    model.add(Dense(units=10, activation="relu"))

    model.compile(loss=SquaredError(), optimizer=GradientDescent(learning_rate=1e-3))

    return model

m, c = 5, 12
linear = lambda x: np.concatenate((x, np.zeros((x.shape[0], 5))), axis=1) * 10



# X = np.random.uniform(size=(20, 5))*10
# y = linear(X)
X =np.array([
    [0.37342291, 0.89042431, 0.16474483, 0.81601524, 0.05943349],
    [0.69314523, 0.45154376, 0.21766751, 0.48943056, 0.33270709],
    [0.56986052, 0.64529707, 0.1391218, 0.42827935, 0.65229916],
    [0.74305514, 0.70814273, 0.72401561, 0.20598358, 0.73261469],
    [0.55444228, 0.33020058, 0.48445992, 0.45348163, 0.96502619],
    [0.37412159, 0.14085241, 0.78346629, 0.00588357, 0.92205353],
    [0.63353835, 0.35270577, 0.61127885, 0.74139291, 0.15091345],
    [0.31639353, 0.46642332, 0.49137373, 0.33449728, 0.42137058],
    [0.83728795, 0.24351749, 0.48754855, 0.47418168, 0.32074814],
    [0.09386686, 0.25263567, 0.47966552, 0.74641435, 0.13526741],
    [0.68944833, 0.92272886, 0.1362212, 0.7020667, 0.89521384],
    [0.55350984, 0.08084388, 0.3076063, 0.29016891, 0.29705208],
    [0.58426477, 0.97859832, 0.08391335, 0.69580241, 0.14345285],
    [0.64031419, 0.8229197, 0.7532648, 0.14426478, 0.60688124],
    [0.97867845, 0.28647657, 0.47322402, 0.65723896, 0.49975968],
    [0.3189266, 0.35047049, 0.87625161, 0.5729564, 0.76918894],
    [0.59218391, 0.49830177, 0.64663148, 0.25750718, 0.37425824],
    
])

y = np.array(
    [
    [0.74081368, 0.46549888, 0.8372765, 0.44271515, 0.40245538, 0.14976449, 0.86711804, 0.50110162, 0.75489766, 0.82356757],
    [0.81987091, 0.61822479, 0.83794259, 0.63744438, 0.02972368, 0.92930079, 0.8480842, 0.59369352, 0.09879105, 0.83266134],
    [0.30651119, 0.31125906, 0.65191553, 0.91710142, 0.13392091, 0.77907166, 0.24559879, 0.26161429, 0.93674655, 0.92971396],
    [0.74889366, 0.2373702, 0.6477897, 0.01209369, 0.01930399, 0.45864839, 0.1306351, 0.49291283, 0.23920955, 0.76385315],
    [0.15994767, 0.35871368, 0.87536971, 0.27413891, 0.00584752, 0.86218792, 0.72889977, 0.37976377, 0.18962971, 0.76038811],
    [0.93694788, 0.96022371, 0.54718498, 0.64172918, 0.9743452, 0.13203104, 0.89770725, 0.96028659, 0.31958727, 0.38477749],
    [0.4144732, 0.70327935, 0.14626437, 0.96314534, 0.93983835, 0.18091178, 0.6023682, 0.27762306, 0.45165653, 0.69392452],
    [0.49938492, 0.54587796, 0.40340108, 0.49256824, 0.94745825, 0.27463982, 0.79687827, 0.41002045, 0.08185699, 0.99420645],
    [0.79287464, 0.76218006, 0.04817571, 0.01431989, 0.94332942, 0.88254636, 0.24512243, 0.93991448, 0.67279402, 0.05001788],
    [0.3507041, 0.46787367, 0.67612314, 0.55129927, 0.05481695, 0.38945145, 0.17617021, 0.38727741, 0.12037861, 0.90276174],
    [0.04251835, 0.93859292, 0.05689142, 0.80837391, 0.31502779, 0.19636561, 0.9770551, 0.02993787, 0.93761967, 0.18068565],
    [0.64822329, 0.20879749, 0.07067463, 0.05831684, 0.00901768, 0.4056835, 0.36421829, 0.18330594, 0.08496268, 0.80865241],
    [0.59493614, 0.45621411, 0.13399002, 0.30639693, 0.05641313, 0.38144688, 0.30374233, 0.48496078, 0.62086729, 0.89191185],
    [0.00440723, 0.0256631, 0.85027018, 0.23269773, 0.99968282, 0.49017634, 0.92991893, 0.23841052, 0.02846811, 0.45601043],
    [0.28436724, 0.12755897, 0.45587013, 0.63295314, 0.43680388, 0.63792616, 0.34525366, 0.27093688, 0.58192016, 0.32178187],
    [0.54683986, 0.67027233, 0.15533466, 0.20618806, 0.63527665, 0.12700752, 0.69976333, 0.55614821, 0.93416679, 0.65704773],
    [0.47060731, 0.32709192, 0.36605539, 0.36905334, 0.91669365, 0.40129441, 0.490115, 0.11774066, 0.01169672, 0.49753191],
]

)


X_val = np.array([[0.48262878, 0.66153688, 0.72521139, 0.19981822, 0.47827814],
    [0.47682251, 0.73232171, 0.66959598, 0.27834694, 0.67240806],
    [0.53034278, 0.29313847, 0.75356527, 0.37260476, 0.41225283]])

y_val = np.array([[0.23637025, 0.82273958, 0.55313443, 0.65091556, 0.03152427, 0.33961996, 0.82966412, 0.50321997, 0.6941072, 0.07343263],
    [0.96485431, 0.4508417, 0.59820356, 0.74207159, 0.19413417, 0.61839915, 0.45129896, 0.11382925, 0.18926571, 0.26083939],
    [0.7025429, 0.10436152, 0.56542394, 0.09496172, 0.1338587, 0.30658647, 0.25992984, 0.64606254, 0.83698226, 0.69317169]])
X.shape, y.shape

model = create_model()

print(X.shape, y.shape)
mse = SquaredError()


print(np.sum(abs(mse.forward(model.predict(X), y))))
print("---------------------------------")

# dx=1e-5

# pred1 = model.predict(X)
# loss1 = (mse.forward(pred1, y))

# print(model._Sequential__layers[1].W_list[0][0][0], loss1.shape)

# model._Sequential__layers[1]._Dense__W[0][0] += dx

# pred2 = model.predict(X)
# loss2 = (mse.forward(pred2, y))
# print(model._Sequential__layers[1]._Dense__W[0][0], loss2.shape)
# # print(model._Sequential__layers[1]._Dense__W.shape)
# print(((loss2-loss1)/dx).shape)

# model._Sequential__layers[1]._Dense__W[0][0] -= dx

# print("differ: ", model._Sequential__layers[1].W_list[0][0][0] - model._Sequential__layers[1]._Dense__W[0][0])
print()

lr_schedule = lr_schedule(lr=1e-3, type="exponential", k=1e-3)

# model = create_model()
model = load_model("model1")
print(model._Sequential__layers[0]._Dense__W[0])
# print(mse.forward(model.predict(X), y).shape)
print("LOSS1", np.sum(abs(mse.forward(model.predict(X), y))))
# model.fit(X, y, epoch=10000, batch_size=100, patient=5, validation=(X_val, y_val))
y_pred = model.predict(X)
loss = (mse.forward(y_pred, y))
print("LOSS2", np.sum(abs(loss)))
# print(model.save[0][0].shape)
# first = (model._Sequential__layers[1].W_list[0][0][0])
# after = (model._Sequential__layers[1].W_list[1][0][0])

# print(first-after)


# print(np.sum(abs(loss2-loss1)/dx))

# print("-------------------------------")
# print(mse.forward(y_pred, y))
# model.fit(X, y)

model.plot_loss()
plt.show()

model.save_model(model=model, name="model1")
